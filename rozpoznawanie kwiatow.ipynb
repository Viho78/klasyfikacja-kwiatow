{"cells":[{"cell_type":"markdown","metadata":{"id":"IImW6xGnwobW"},"source":["# Obraz - transfer learning - praca domowa\n","Ostatnia aktualizacja: 2022.12.10\n","\n","Z dokumentacji [Keras](https://keras.io/guides/transfer_learning/): *Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem.*\n","\n","Głównym celem pracy domowej jest stworzenie klasyfikatora, który będzie odróżniał zdjęcia obiektów w wybranym przez nas zbiorze. Użyjemy do tego jednego z [gotowych modeli Keras](https://keras.io/api/applications/), wytrenowanego wcześniej na zbiorze Imagenet. \n","\n","Przydatne źródła:\n","- [transfer learning vgg16 + tf_flowers](https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4)\n","- [Keras - transfer learning](https://keras.io/guides/transfer_learning/)"]},{"cell_type":"markdown","source":["### Wybierz swój zbiór danych### \n","Chcemy mieć co najmniej 2-3 klasy. Możesz użyć gotowego zbioru (np. z [katalogu tensorflow](https://www.tensorflow.org/datasets/catalog/overview) lub [kaggle](https://www.kaggle.com/datasets)) albo użyć własnych danych. \n","- [Przykładowy zbiór: tf_flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers). \n","- [Przykładowy zbiór: plant_leaves](https://www.tensorflow.org/datasets/catalog/plant_leaves). \n","\n","Wczytaj i przygotuj dane do treningu. \n","\n"],"metadata":{"id":"B_VaMT6Ixv2P"}},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow.keras.utils import to_categorical\n","\n","(train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n","    \"tf_flowers\",\n","    split=[\"train[:70%]\", \"train[:30%]\"],\n","    batch_size=-1,\n","    as_supervised=True,\n",")\n","\n","train_ds = tf.image.resize(train_ds, (150, 150))\n","test_ds = tf.image.resize(test_ds, (150, 150))\n","\n","train_labels = to_categorical(train_labels, num_classes=5)\n","test_labels = to_categorical(test_labels, num_classes=5)\n"],"metadata":{"id":"Ow2vnvNPXQl2","executionInfo":{"status":"ok","timestamp":1674148689601,"user_tz":-60,"elapsed":36514,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}},"colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["0d9c0bd072fb4e8085aa9eb78f48e7cb","5a48e7fd1a3d4419927830d2effdb2ab","8aec5db6a9224d7088a26cd29d91dbdd","d4be86ddbced494a944fdb5cd0b6f29f","7c1e21303e6d42638df9fc2203b9fa9e","bd1086e6659b4531b1b8dbbee749f7e3","e2d2f32722d84a02bc1fba4566e3e6d7","9c7c14aeafc948a38f340a2043f9950c","a183270a0a66476486444e1303692c4d","ed6d4694b84c4320a0691bca977deb10","341d982240754999bb8f5392922c7a63"]},"outputId":"ae74cc1e-1d30-4eb5-c3b8-532762e29359"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to /root/tensorflow_datasets/tf_flowers/3.0.1...\n"]},{"output_type":"display_data","data":{"text/plain":["Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d9c0bd072fb4e8085aa9eb78f48e7cb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\n"]}]},{"cell_type":"code","source":["print(train_ds[1][1][149])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOQNHRuR-mL1","executionInfo":{"status":"ok","timestamp":1674148690310,"user_tz":-60,"elapsed":716,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}},"outputId":"c4b77059-f9b4-42d1-f707-fa94eb07467c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["### Wczytaj wytrenowany model do klasyfikacji obrazu. ###\n","Może to być jeden z gotowych [modeli dostępnych w Keras](https://keras.io/api/applications/). Wczytujemy go z wytrenowanymi już wcześniej wagami na Imagenecie (weights='imagenet'). \n","\n","Model możemy wczytać bez ostatnich warstw (include_top=False) i dodać je potem ręcznie, dostosowane do liczby klas w naszym zbiorze. Imagenet ma 1000 klas, my prawdopodobnie będziemy mieć ich mniej. \n","\n","Pamiętaj, żeby wyłączyć lub ograniczyć trening części modelu z wytrenowanymi już wagami (trainable=False). "],"metadata":{"id":"BAo9-ecevKWT"}},{"cell_type":"code","source":["model1 = tf.keras.applications.EfficientNetB7(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=train_ds[0].shape,\n","    pooling=None,\n","    classes=1000,\n","    classifier_activation=\"softmax\",\n",")\n","model1.trainable = False"],"metadata":{"id":"IccXldfvxvYH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674148702018,"user_tz":-60,"elapsed":11709,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}},"outputId":"76e1bda1-c18d-408a-b461-9405f457e36f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n","258076736/258076736 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"markdown","source":["### Zadanie 1: Wytrenuj model na swoich danych ###\n","**(Zadanie na ocenę 3)**\n","\n","Wytrenuj wybrany model na swoich danych. Omów eksperyment i wyniki (100 słów). "],"metadata":{"id":"LgWoGVFJ2BA5"}},{"cell_type":"code","source":["from tensorflow.keras import layers, models\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","flatten_layer = layers.Flatten()\n","dense_layer_1 = layers.Dense(50, activation='relu')\n","dense_layer_2 = layers.Dense(20, activation='relu')\n","prediction_layer = layers.Dense(5, activation='softmax')\n","\n","\n","model = models.Sequential([\n","    model1,\n","    flatten_layer,\n","    dense_layer_1,\n","    dense_layer_2,\n","    prediction_layer\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy'],\n",")\n","\n","es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n","\n","model.fit(train_ds, train_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])\n","\n","print(\"/n/n\")\n","model.evaluate(train_ds, train_labels)\n","model.evaluate(test_ds, test_labels)"],"metadata":{"id":"ceCsNpA42H7Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674148952299,"user_tz":-60,"elapsed":250284,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}},"outputId":"64cb53cc-b60a-4a0e-de93-84a9a4b0a1c6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","65/65 [==============================] - 48s 338ms/step - loss: 2.2484 - accuracy: 0.4394 - val_loss: 1.0126 - val_accuracy: 0.6206\n","Epoch 2/50\n","65/65 [==============================] - 16s 244ms/step - loss: 0.9161 - accuracy: 0.6540 - val_loss: 1.0764 - val_accuracy: 0.6342\n","Epoch 3/50\n","65/65 [==============================] - 18s 280ms/step - loss: 0.7739 - accuracy: 0.7182 - val_loss: 0.9465 - val_accuracy: 0.6634\n","Epoch 4/50\n","65/65 [==============================] - 18s 282ms/step - loss: 0.6444 - accuracy: 0.7630 - val_loss: 0.8088 - val_accuracy: 0.7276\n","Epoch 5/50\n","65/65 [==============================] - 16s 249ms/step - loss: 0.5637 - accuracy: 0.7903 - val_loss: 0.9699 - val_accuracy: 0.6751\n","Epoch 6/50\n","65/65 [==============================] - 16s 249ms/step - loss: 0.7044 - accuracy: 0.7358 - val_loss: 1.0509 - val_accuracy: 0.6732\n","Epoch 7/50\n","65/65 [==============================] - 16s 245ms/step - loss: 0.4600 - accuracy: 0.8282 - val_loss: 0.9870 - val_accuracy: 0.6732\n","Epoch 8/50\n","65/65 [==============================] - 16s 244ms/step - loss: 0.4467 - accuracy: 0.8433 - val_loss: 0.8126 - val_accuracy: 0.7257\n","Epoch 9/50\n","65/65 [==============================] - 18s 285ms/step - loss: 0.3654 - accuracy: 0.8701 - val_loss: 1.0095 - val_accuracy: 0.6673\n","/n/n\n","81/81 [==============================] - 17s 203ms/step - loss: 0.5353 - accuracy: 0.8097\n","35/35 [==============================] - 8s 221ms/step - loss: 0.4658 - accuracy: 0.8329\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.4657512307167053, 0.8328791856765747]"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Jako zbiór wybrałem tensorflow Kwaity a jako model EfficientNetB7. Przy parametrach z tutoriala nosiagnął on całkiem dobre wyniki, ponieważ evaluate na zbiorze testowym wyniosło ok. 0,8. \n","Model został wgrany jako Model1 z parametrami jak w poleceniu: wagi z imagnetu, bez ostatniej warstwy, na 1000 klas oraz ograniczeniem treningu. Następnie wytrenowany z trzema wartstwami, dwie relu i jedna softmax. Został również dodany early stopping ze względu na to, że model jest już wytrenowany więc nie powinnien potrzebować zbyt dużo iteracji. \n","Wyniki accuracy oraz loss nie są idealne, myślę że wynika to z trudności zbioru. Łatwiej byłoby na pewno odróżniać przedmiot or roślini a nie gatunki roślin, niemniej z pewnością wyuczony model przy tych wynikach poradził by sobie lepiej niż przeciętny człowiek nieznający nawet nazw kwiatów. "],"metadata":{"id":"t-jcAR_Y3mwN"}},{"cell_type":"markdown","source":["### Zadanie 2: Dodatkowe sieci ###\n","**(Zadanie na ocenę 4, po wykonaniu  zadania 1)**\n","\n","Przeprowadź to samo na dwóch dodatkowych sieciach i omów wyniki (100 słów). \n","\n","Czyli jeśli w zadaniu 1 użyliśmy np. VGG to teraz wybieramy sobie np. ResNet i MobileNet. "],"metadata":{"id":"YMwQtLDyyBIn"}},{"cell_type":"code","source":["model2 = tf.keras.applications.ResNet50V2(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=train_ds[0].shape,\n","    pooling=None,\n","    classes=1000,\n","    classifier_activation=\"softmax\",\n",")\n","model2.trainable = False\n","\n","model3 = tf.keras.applications.ResNet152V2(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=train_ds[0].shape,\n","    pooling=None,\n","    classes=1000,\n","    classifier_activation=\"softmax\",\n",")\n","model3.trainable = False"],"metadata":{"id":"XaTwND6n26Fe","executionInfo":{"status":"ok","timestamp":1674150317325,"user_tz":-60,"elapsed":6816,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["flatten_layer = layers.Flatten()\n","dense_layer_1 = layers.Dense(60, activation='relu')\n","dense_layer_2 = layers.Dense(30, activation='relu')\n","dense_layer_3 = layers.Dense(10, activation='relu')\n","prediction_layer = layers.Dense(5, activation='softplus')\n","\n","\n","model = models.Sequential([\n","    model2,\n","    flatten_layer,\n","    dense_layer_1,\n","    dense_layer_2,\n","    dense_layer_3,\n","    prediction_layer\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy'],\n",")\n","\n","es = EarlyStopping(monitor='val_accuracy', mode='max', patience=10,  restore_best_weights=True)\n","\n","model.fit(train_ds, train_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])\n","\n","print(\"/n/n\")\n","model.evaluate(train_ds, train_labels)\n","model.evaluate(test_ds, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qgrmwQ41LWQ9","executionInfo":{"status":"ok","timestamp":1674149455014,"user_tz":-60,"elapsed":151505,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}},"outputId":"6f6d3936-9e1a-40c3-fdf7-51937945bb3e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","65/65 [==============================] - 8s 80ms/step - loss: 4.5797 - accuracy: 0.2399 - val_loss: 4.0378 - val_accuracy: 0.2549\n","Epoch 2/50\n","65/65 [==============================] - 4s 65ms/step - loss: 4.4970 - accuracy: 0.2579 - val_loss: 4.0230 - val_accuracy: 0.2665\n","Epoch 3/50\n","65/65 [==============================] - 4s 66ms/step - loss: 4.4777 - accuracy: 0.2856 - val_loss: 4.0078 - val_accuracy: 0.2918\n","Epoch 4/50\n","65/65 [==============================] - 5s 73ms/step - loss: 4.4493 - accuracy: 0.3294 - val_loss: 4.0359 - val_accuracy: 0.3307\n","Epoch 5/50\n","65/65 [==============================] - 4s 65ms/step - loss: 2.7094 - accuracy: 0.2910 - val_loss: 1.5767 - val_accuracy: 0.1848\n","Epoch 6/50\n","65/65 [==============================] - 4s 65ms/step - loss: 1.5289 - accuracy: 0.2706 - val_loss: 1.9175 - val_accuracy: 0.1829\n","Epoch 7/50\n","65/65 [==============================] - 4s 65ms/step - loss: 1.5679 - accuracy: 0.3290 - val_loss: 1.5739 - val_accuracy: 0.3191\n","Epoch 8/50\n","65/65 [==============================] - 5s 72ms/step - loss: 1.5153 - accuracy: 0.3465 - val_loss: 1.5410 - val_accuracy: 0.3113\n","Epoch 9/50\n","65/65 [==============================] - 4s 65ms/step - loss: 1.5033 - accuracy: 0.3781 - val_loss: 2.9762 - val_accuracy: 0.2724\n","Epoch 10/50\n","65/65 [==============================] - 4s 65ms/step - loss: 1.6961 - accuracy: 0.2550 - val_loss: 1.5538 - val_accuracy: 0.2568\n","Epoch 11/50\n","65/65 [==============================] - 4s 64ms/step - loss: 1.5066 - accuracy: 0.2642 - val_loss: 1.5105 - val_accuracy: 0.2743\n","Epoch 12/50\n","65/65 [==============================] - 4s 64ms/step - loss: 1.4478 - accuracy: 0.2769 - val_loss: 1.4674 - val_accuracy: 0.2860\n","Epoch 13/50\n","65/65 [==============================] - 4s 65ms/step - loss: 1.3905 - accuracy: 0.3601 - val_loss: 1.5391 - val_accuracy: 0.3385\n","Epoch 14/50\n","65/65 [==============================] - 4s 66ms/step - loss: 1.3730 - accuracy: 0.4506 - val_loss: 1.5345 - val_accuracy: 0.4280\n","Epoch 15/50\n","65/65 [==============================] - 4s 66ms/step - loss: 1.3315 - accuracy: 0.4603 - val_loss: 1.6593 - val_accuracy: 0.4358\n","Epoch 16/50\n","65/65 [==============================] - 4s 65ms/step - loss: 1.3177 - accuracy: 0.4900 - val_loss: 1.5922 - val_accuracy: 0.4455\n","Epoch 17/50\n","65/65 [==============================] - 4s 63ms/step - loss: 1.3689 - accuracy: 0.4637 - val_loss: 1.6883 - val_accuracy: 0.2393\n","Epoch 18/50\n","65/65 [==============================] - 4s 63ms/step - loss: 1.5437 - accuracy: 0.2934 - val_loss: 1.5485 - val_accuracy: 0.2860\n","Epoch 19/50\n","65/65 [==============================] - 4s 63ms/step - loss: 1.4846 - accuracy: 0.3046 - val_loss: 1.5072 - val_accuracy: 0.2938\n","Epoch 20/50\n","65/65 [==============================] - 4s 63ms/step - loss: 1.4436 - accuracy: 0.3363 - val_loss: 1.5257 - val_accuracy: 0.3521\n","Epoch 21/50\n","65/65 [==============================] - 4s 64ms/step - loss: 1.4036 - accuracy: 0.3908 - val_loss: 1.5242 - val_accuracy: 0.3930\n","Epoch 22/50\n","65/65 [==============================] - 4s 63ms/step - loss: 1.3640 - accuracy: 0.4414 - val_loss: 1.5332 - val_accuracy: 0.4066\n","Epoch 23/50\n","65/65 [==============================] - 4s 64ms/step - loss: 2.6029 - accuracy: 0.3212 - val_loss: 4.2376 - val_accuracy: 0.2043\n","Epoch 24/50\n","65/65 [==============================] - 5s 71ms/step - loss: 1.8243 - accuracy: 0.2925 - val_loss: 1.5633 - val_accuracy: 0.3113\n","Epoch 25/50\n","65/65 [==============================] - 4s 64ms/step - loss: 1.5175 - accuracy: 0.3650 - val_loss: 1.5211 - val_accuracy: 0.3463\n","Epoch 26/50\n","65/65 [==============================] - 4s 67ms/step - loss: 1.4757 - accuracy: 0.3635 - val_loss: 1.4842 - val_accuracy: 0.3482\n","/n/n\n","81/81 [==============================] - 4s 50ms/step - loss: 1.3017 - accuracy: 0.5045\n","35/35 [==============================] - 2s 50ms/step - loss: 1.2072 - accuracy: 0.5341\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.207165241241455, 0.5340599417686462]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["flatten_layer = layers.Flatten()\n","dense_layer_1 = layers.Dense(60, activation='relu')\n","dense_layer_2 = layers.Dense(40, activation='relu')\n","dense_layer_3 = layers.Dense(20, activation='relu')\n","dense_layer_4 = layers.Dense(10, activation='relu')\n","prediction_layer = layers.Dense(5, activation='softmax')\n","\n","\n","model = models.Sequential([\n","    model3,\n","    flatten_layer,\n","    dense_layer_1,\n","    dense_layer_2,\n","    dense_layer_3,\n","    prediction_layer\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy'],\n",")\n","\n","es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n","\n","model.fit(train_ds, train_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[es])\n","\n","print(\"/n/n\")\n","model.evaluate(train_ds, train_labels)\n","model.evaluate(test_ds, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2MnqVqQLVpn","executionInfo":{"status":"ok","timestamp":1674150493679,"user_tz":-60,"elapsed":176359,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}},"outputId":"c1fd804a-4e64-4aeb-dd1a-720772526a8b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","65/65 [==============================] - 22s 207ms/step - loss: 145.2508 - accuracy: 0.2589 - val_loss: 111.3391 - val_accuracy: 0.2471\n","Epoch 2/50\n","65/65 [==============================] - 11s 169ms/step - loss: 44.7720 - accuracy: 0.2818 - val_loss: 20.3724 - val_accuracy: 0.2918\n","Epoch 3/50\n","65/65 [==============================] - 11s 173ms/step - loss: 20.1206 - accuracy: 0.3319 - val_loss: 33.7761 - val_accuracy: 0.2451\n","Epoch 4/50\n","65/65 [==============================] - 11s 170ms/step - loss: 22.6072 - accuracy: 0.3630 - val_loss: 16.8909 - val_accuracy: 0.3872\n","Epoch 5/50\n","65/65 [==============================] - 11s 164ms/step - loss: 13.2274 - accuracy: 0.4034 - val_loss: 16.2878 - val_accuracy: 0.3677\n","Epoch 6/50\n","65/65 [==============================] - 11s 171ms/step - loss: 15.2012 - accuracy: 0.3839 - val_loss: 21.0091 - val_accuracy: 0.3113\n","Epoch 7/50\n","65/65 [==============================] - 11s 163ms/step - loss: 10.1798 - accuracy: 0.4292 - val_loss: 19.2193 - val_accuracy: 0.2860\n","Epoch 8/50\n","65/65 [==============================] - 11s 167ms/step - loss: 11.9670 - accuracy: 0.3971 - val_loss: 20.7400 - val_accuracy: 0.2685\n","Epoch 9/50\n","65/65 [==============================] - 11s 172ms/step - loss: 10.6238 - accuracy: 0.3484 - val_loss: 5.1601 - val_accuracy: 0.3093\n","/n/n\n","81/81 [==============================] - 11s 132ms/step - loss: 14.2724 - accuracy: 0.4212\n","35/35 [==============================] - 5s 131ms/step - loss: 13.9583 - accuracy: 0.4242\n"]},{"output_type":"execute_result","data":{"text/plain":["[13.958308219909668, 0.42415985465049744]"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["V1 stara wersja\n","\n","---\n","\n","\n","W kolejnych eksperymentach zdecydowałem się już na inne modele - ResNet50V2 oraz ResNet152V2 w celu porównania dwóch modeli z tej samej grupy. W teori 152V2 powinien sobie poradzić nieco lepiej niż 50V2 co chciałbym zaobserwować. Zmieniłem też parametry uczenia oraz dodałem jedną wartwę. Oczywiście modele 2 i 3 będą porównywane z wcześniejszym model1 EfficientNetB7.\n","Po treniowaniu na kwiatach wyniki modeli 2 i 3 okazały się bardzo słabe (accuracy 0.32 oraz 0.26) oraz dodatkowo odwrotne od moich oczekiwań. Model 50V2 powinien być gorszy niż 152V2 a poradził sobie sporo lepiej w accuracy bo aż o 0.06 punktu lepiej. Nie zmienia to faktu że moje stwierdzenie z zadania 1, że model poradzi sobie lepiej z rozpoznawaniem kwiatów od człowieka przestaje być prawdziwe dla tych modeli. Model 2 i 3 w przypadku kwiatów się nie sprawdziły, możliwe też że zmiany parametów oraz dodanie warsty mogły w tym przeszkodzić."],"metadata":{"id":"68eGKyM132xk"}},{"cell_type":"markdown","source":["V2 nowa wersja po poprawie\n","\n","\n","---\n","\n","\n","\n","W kolejnych eksperymentach zdecydowałem się już na inne modele - ResNet50V2 oraz ResNet152V2 w celu porównania dwóch modeli z tej samej grupy. W teori 152V2 powinien sobie poradzić nieco lepiej niż 50V2 co chciałbym zaobserwować. Zmieniłem też parametry uczenia oraz dodałem jedną wartwę. Oczywiście modele 2 i 3 będą porównywane z wcześniejszym modelem EfficientNetB7. W porównaniu z wersją pierwszą z przed poprawy, gdzie accuracy wynosiło 0.20-0.30 zmieniłem warstwy oraz funkcje aktywacyjną ostatniej warstwy na softplus. \n","\n","\n","---\n","\n","\n","Po treniowaniu na kwiatach wyniki modeli 2 i 3 okazały się nieco słabsze (0.53 oraz 0.42) niż EfficientNetB7, ale lepsze niż poprzednie wyniki bliskie losowym wyborom. Model 50V2 powinien być gorszy niż 152V2 a poradził sobie sporo lepiej w accuracy bo aż o 0.09 punktu lepiej. W tym przypadku stwierdzenie z zadania 1 nadal ma sens. Zwykły człowiek nieznający się na kwiatach poradzi sobie gorzej, ale w odróżeniu od modelu z zadania 1 średnio obeznana z roślinami osoba może modele z zadania 2 pokonać."],"metadata":{"id":"YaNzGcxiFxBl"}},{"cell_type":"markdown","source":["### Zadanie 3: Trening od zera i porównanie ###\n","**(Zadanie na ocenę 5, po wykonaniu zadania 1 i 2)**\n","\n","Spróbuj skonstruować swój własny model i wytrenować go 'od zera' na tych samych danych. Porównaj i omów swój ekeperyment i wyniki (100 słów)."],"metadata":{"id":"-YbAVdOX2yL_"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.python.ops.numpy_ops import np_config\n","from keras.utils.np_utils import to_categorical\n","\n","np_config.enable_numpy_behavior()\n","\n","(X_train, y_train), (X_test, y_test) = tfds.load(\n","    \"tf_flowers\",\n","    split=[\"train[:70%]\", \"train[:30%]\"],\n","    batch_size=-1,\n","    as_supervised=True,\n",")\n","\n","\n","\n","X_train = tf.image.resize(X_train, (32, 32))\n","X_test = tf.image.resize(X_test, (32, 32))\n","\n","#y_train = to_categorical(y_train, num_classes=10)\n","#y_test = to_categorical(y_test, num_classes=10)\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)\n","\n","print(\"min: {}, max:{}\".format(np.min(X_train), np.max(X_train)))\n","X_train = X_train.astype('float32') / np.max(X_train)\n","X_test = X_test.astype('float32') / np.max(X_test)\n","print(\"min: {}, max:{}\".format(np.min(X_train), np.max(X_train)))\n","\n","\n","Y_train = to_categorical(y_train)\n","Y_test = to_categorical(y_test)\n","\n","print(y_train[0])\n","print(Y_train[0])"],"metadata":{"id":"lXGDTBURyAS4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671354841146,"user_tz":-60,"elapsed":7233,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}},"outputId":"c6caa3cc-4c9f-4d24-d255-dedc988b45ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2569, 32, 32, 3)\n","(1101, 32, 32, 3)\n","(2569,)\n","(1101,)\n","min: 0.0, max:255.0\n","min: 0.0, max:1.0\n","tf.Tensor(2, shape=(), dtype=int64)\n","[0. 0. 1. 0. 0.]\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import layers, models\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from tensorflow.keras.callbacks import EarlyStopping\n","from keras.layers import  BatchNormalization\n","from keras.layers import RandomFlip\n","from keras.layers import RandomZoom\n","from tensorflow.keras.layers import Dropout\n","from keras.layers import Dense, Flatten\n","\n","model_mega = Sequential([\n","    RandomFlip(\"horizontal\", input_shape=(32, 32, 3)),\n","    RandomZoom(0.2, 0.2),\n","\n","    Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'),\n","    BatchNormalization(),\n","    Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'),\n","    BatchNormalization(),\n","    MaxPooling2D(pool_size=(2,2)),\n","    Dropout(0.2),\n","\n","\n","    Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n","    BatchNormalization(),\n","    Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n","    BatchNormalization(),\n","    MaxPooling2D(pool_size=(2,2)),\n","    Dropout(0.2),\n","\n","\n","    Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n","    BatchNormalization(),\n","    Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'),\n","    BatchNormalization(),\n","    MaxPooling2D(pool_size=(2,2)),\n","    Dropout(0.2),\n","\n","    #konczymy filtrowanie, feature extraction itp i zaczyna sie normalny, klasyczny klasyfikator\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(5, activation='softmax')\n","], name=\"model_mega\")\n","\n","model_mega.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","es = EarlyStopping(patience=10, monitor=\"val_loss\")"],"metadata":{"id":"erVh0NpRcDOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_mega.fit(X_train, Y_train, epochs=100, batch_size=256, validation_split=0.1, \n","               #callbacks=[es]\n","               )\n","\n","model_mega.evaluate(X_train, Y_train)\n","model_mega.evaluate(X_test, Y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a60S3NJdeG91","executionInfo":{"status":"ok","timestamp":1671355086811,"user_tz":-60,"elapsed":144805,"user":{"displayName":"Juliusz Stańczyk","userId":"03688363158834009741"}},"outputId":"d6836403-abd4-405f-f48a-07ee83efd515"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","10/10 [==============================] - 2s 151ms/step - loss: 1.2300 - accuracy: 0.4905 - val_loss: 3.7443 - val_accuracy: 0.2296\n","Epoch 2/100\n","10/10 [==============================] - 2s 218ms/step - loss: 1.1555 - accuracy: 0.5381 - val_loss: 4.3622 - val_accuracy: 0.2296\n","Epoch 3/100\n","10/10 [==============================] - 1s 141ms/step - loss: 1.1182 - accuracy: 0.5346 - val_loss: 4.0952 - val_accuracy: 0.2296\n","Epoch 4/100\n","10/10 [==============================] - 1s 136ms/step - loss: 1.1228 - accuracy: 0.5324 - val_loss: 4.8759 - val_accuracy: 0.2296\n","Epoch 5/100\n","10/10 [==============================] - 1s 139ms/step - loss: 1.1121 - accuracy: 0.5528 - val_loss: 4.7464 - val_accuracy: 0.2296\n","Epoch 6/100\n","10/10 [==============================] - 1s 137ms/step - loss: 1.1159 - accuracy: 0.5484 - val_loss: 4.2432 - val_accuracy: 0.2296\n","Epoch 7/100\n","10/10 [==============================] - 1s 145ms/step - loss: 1.1875 - accuracy: 0.5104 - val_loss: 4.3974 - val_accuracy: 0.2296\n","Epoch 8/100\n","10/10 [==============================] - 1s 142ms/step - loss: 1.1089 - accuracy: 0.5497 - val_loss: 4.0787 - val_accuracy: 0.2296\n","Epoch 9/100\n","10/10 [==============================] - 1s 141ms/step - loss: 1.1050 - accuracy: 0.5476 - val_loss: 4.4256 - val_accuracy: 0.2296\n","Epoch 10/100\n","10/10 [==============================] - 1s 142ms/step - loss: 1.1255 - accuracy: 0.5437 - val_loss: 4.1751 - val_accuracy: 0.2296\n","Epoch 11/100\n","10/10 [==============================] - 1s 142ms/step - loss: 1.1195 - accuracy: 0.5666 - val_loss: 4.3109 - val_accuracy: 0.2296\n","Epoch 12/100\n","10/10 [==============================] - 1s 141ms/step - loss: 1.0449 - accuracy: 0.5718 - val_loss: 4.6727 - val_accuracy: 0.2296\n","Epoch 13/100\n","10/10 [==============================] - 1s 142ms/step - loss: 1.0326 - accuracy: 0.5943 - val_loss: 4.3255 - val_accuracy: 0.2296\n","Epoch 14/100\n","10/10 [==============================] - 1s 140ms/step - loss: 1.1111 - accuracy: 0.5714 - val_loss: 3.3189 - val_accuracy: 0.2296\n","Epoch 15/100\n","10/10 [==============================] - 1s 141ms/step - loss: 1.0109 - accuracy: 0.6038 - val_loss: 4.1308 - val_accuracy: 0.2296\n","Epoch 16/100\n","10/10 [==============================] - 1s 140ms/step - loss: 1.0026 - accuracy: 0.5952 - val_loss: 4.9012 - val_accuracy: 0.2296\n","Epoch 17/100\n","10/10 [==============================] - 1s 149ms/step - loss: 0.9594 - accuracy: 0.6276 - val_loss: 3.7691 - val_accuracy: 0.2296\n","Epoch 18/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.9489 - accuracy: 0.6272 - val_loss: 3.0284 - val_accuracy: 0.2296\n","Epoch 19/100\n","10/10 [==============================] - 1s 135ms/step - loss: 0.9541 - accuracy: 0.6189 - val_loss: 3.1430 - val_accuracy: 0.2296\n","Epoch 20/100\n","10/10 [==============================] - 1s 140ms/step - loss: 0.9428 - accuracy: 0.6332 - val_loss: 3.3320 - val_accuracy: 0.2296\n","Epoch 21/100\n","10/10 [==============================] - 1s 147ms/step - loss: 0.9494 - accuracy: 0.6306 - val_loss: 3.1720 - val_accuracy: 0.2296\n","Epoch 22/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.9200 - accuracy: 0.6419 - val_loss: 4.6316 - val_accuracy: 0.2296\n","Epoch 23/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.9197 - accuracy: 0.6388 - val_loss: 5.2527 - val_accuracy: 0.2296\n","Epoch 24/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.9539 - accuracy: 0.6207 - val_loss: 4.2039 - val_accuracy: 0.2296\n","Epoch 25/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.9526 - accuracy: 0.6129 - val_loss: 2.5701 - val_accuracy: 0.2296\n","Epoch 26/100\n","10/10 [==============================] - 1s 136ms/step - loss: 0.9929 - accuracy: 0.5952 - val_loss: 2.7196 - val_accuracy: 0.2296\n","Epoch 27/100\n","10/10 [==============================] - 1s 144ms/step - loss: 1.0181 - accuracy: 0.5861 - val_loss: 4.0789 - val_accuracy: 0.2296\n","Epoch 28/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.9514 - accuracy: 0.6267 - val_loss: 2.3276 - val_accuracy: 0.2451\n","Epoch 29/100\n","10/10 [==============================] - 1s 140ms/step - loss: 0.9165 - accuracy: 0.6453 - val_loss: 2.2825 - val_accuracy: 0.2840\n","Epoch 30/100\n","10/10 [==============================] - 1s 140ms/step - loss: 0.9247 - accuracy: 0.6367 - val_loss: 2.1703 - val_accuracy: 0.2918\n","Epoch 31/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.9151 - accuracy: 0.6380 - val_loss: 2.4115 - val_accuracy: 0.2685\n","Epoch 32/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.9348 - accuracy: 0.6319 - val_loss: 2.0791 - val_accuracy: 0.3113\n","Epoch 33/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.8990 - accuracy: 0.6458 - val_loss: 2.2103 - val_accuracy: 0.3074\n","Epoch 34/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.8785 - accuracy: 0.6548 - val_loss: 2.6841 - val_accuracy: 0.3268\n","Epoch 35/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.9290 - accuracy: 0.6324 - val_loss: 2.2676 - val_accuracy: 0.3463\n","Epoch 36/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.9293 - accuracy: 0.6306 - val_loss: 2.3404 - val_accuracy: 0.3385\n","Epoch 37/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.8932 - accuracy: 0.6566 - val_loss: 2.2311 - val_accuracy: 0.3113\n","Epoch 38/100\n","10/10 [==============================] - 1s 145ms/step - loss: 0.9270 - accuracy: 0.6445 - val_loss: 2.0229 - val_accuracy: 0.3541\n","Epoch 39/100\n","10/10 [==============================] - 1s 143ms/step - loss: 0.9091 - accuracy: 0.6505 - val_loss: 1.9407 - val_accuracy: 0.4241\n","Epoch 40/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.9272 - accuracy: 0.6406 - val_loss: 2.2010 - val_accuracy: 0.3774\n","Epoch 41/100\n","10/10 [==============================] - 1s 140ms/step - loss: 0.9103 - accuracy: 0.6553 - val_loss: 2.9590 - val_accuracy: 0.3113\n","Epoch 42/100\n","10/10 [==============================] - 1s 140ms/step - loss: 0.9189 - accuracy: 0.6488 - val_loss: 3.5594 - val_accuracy: 0.2685\n","Epoch 43/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.8602 - accuracy: 0.6730 - val_loss: 1.8460 - val_accuracy: 0.4591\n","Epoch 44/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.8677 - accuracy: 0.6665 - val_loss: 2.1799 - val_accuracy: 0.4086\n","Epoch 45/100\n","10/10 [==============================] - 1s 144ms/step - loss: 0.8467 - accuracy: 0.6618 - val_loss: 2.4997 - val_accuracy: 0.3891\n","Epoch 46/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.8471 - accuracy: 0.6631 - val_loss: 2.9238 - val_accuracy: 0.3658\n","Epoch 47/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.8704 - accuracy: 0.6492 - val_loss: 3.1599 - val_accuracy: 0.4241\n","Epoch 48/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.8663 - accuracy: 0.6760 - val_loss: 2.4815 - val_accuracy: 0.4825\n","Epoch 49/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.8409 - accuracy: 0.6752 - val_loss: 0.9910 - val_accuracy: 0.6226\n","Epoch 50/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.8296 - accuracy: 0.6856 - val_loss: 0.9225 - val_accuracy: 0.6459\n","Epoch 51/100\n","10/10 [==============================] - 1s 143ms/step - loss: 0.8040 - accuracy: 0.6942 - val_loss: 1.0569 - val_accuracy: 0.6381\n","Epoch 52/100\n","10/10 [==============================] - 1s 143ms/step - loss: 0.8003 - accuracy: 0.6881 - val_loss: 0.9492 - val_accuracy: 0.6342\n","Epoch 53/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.7973 - accuracy: 0.6929 - val_loss: 0.9448 - val_accuracy: 0.6459\n","Epoch 54/100\n","10/10 [==============================] - 1s 136ms/step - loss: 0.7995 - accuracy: 0.6877 - val_loss: 1.0717 - val_accuracy: 0.6148\n","Epoch 55/100\n","10/10 [==============================] - 1s 143ms/step - loss: 0.7734 - accuracy: 0.7067 - val_loss: 1.4641 - val_accuracy: 0.5564\n","Epoch 56/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.7598 - accuracy: 0.7011 - val_loss: 1.8811 - val_accuracy: 0.5331\n","Epoch 57/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.7932 - accuracy: 0.7020 - val_loss: 1.0661 - val_accuracy: 0.6031\n","Epoch 58/100\n","10/10 [==============================] - 1s 135ms/step - loss: 0.8085 - accuracy: 0.6791 - val_loss: 0.8496 - val_accuracy: 0.6459\n","Epoch 59/100\n","10/10 [==============================] - 1s 143ms/step - loss: 0.8869 - accuracy: 0.6479 - val_loss: 0.9903 - val_accuracy: 0.6226\n","Epoch 60/100\n","10/10 [==============================] - 2s 149ms/step - loss: 0.8376 - accuracy: 0.6795 - val_loss: 1.2985 - val_accuracy: 0.5720\n","Epoch 61/100\n","10/10 [==============================] - 1s 144ms/step - loss: 0.8503 - accuracy: 0.6648 - val_loss: 0.9447 - val_accuracy: 0.6615\n","Epoch 62/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.8880 - accuracy: 0.6488 - val_loss: 0.7903 - val_accuracy: 0.7043\n","Epoch 63/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.8224 - accuracy: 0.6847 - val_loss: 0.7833 - val_accuracy: 0.6965\n","Epoch 64/100\n","10/10 [==============================] - 1s 136ms/step - loss: 0.8158 - accuracy: 0.6825 - val_loss: 0.8202 - val_accuracy: 0.6887\n","Epoch 65/100\n","10/10 [==============================] - 1s 136ms/step - loss: 0.8327 - accuracy: 0.6717 - val_loss: 0.8548 - val_accuracy: 0.6770\n","Epoch 66/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.8576 - accuracy: 0.6670 - val_loss: 0.9191 - val_accuracy: 0.6576\n","Epoch 67/100\n","10/10 [==============================] - 1s 137ms/step - loss: 0.8104 - accuracy: 0.6773 - val_loss: 0.8149 - val_accuracy: 0.6887\n","Epoch 68/100\n","10/10 [==============================] - 1s 136ms/step - loss: 0.8001 - accuracy: 0.6821 - val_loss: 0.9064 - val_accuracy: 0.6848\n","Epoch 69/100\n","10/10 [==============================] - 1s 136ms/step - loss: 0.7842 - accuracy: 0.6899 - val_loss: 0.8031 - val_accuracy: 0.7198\n","Epoch 70/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.8034 - accuracy: 0.6799 - val_loss: 1.4808 - val_accuracy: 0.4825\n","Epoch 71/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.8393 - accuracy: 0.6713 - val_loss: 1.1359 - val_accuracy: 0.6031\n","Epoch 72/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.8125 - accuracy: 0.6704 - val_loss: 0.9337 - val_accuracy: 0.6226\n","Epoch 73/100\n","10/10 [==============================] - 1s 137ms/step - loss: 0.7695 - accuracy: 0.7046 - val_loss: 1.2216 - val_accuracy: 0.5642\n","Epoch 74/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.8093 - accuracy: 0.6773 - val_loss: 1.1992 - val_accuracy: 0.6109\n","Epoch 75/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.8463 - accuracy: 0.6644 - val_loss: 1.0259 - val_accuracy: 0.6070\n","Epoch 76/100\n","10/10 [==============================] - 1s 140ms/step - loss: 0.7791 - accuracy: 0.6985 - val_loss: 1.4851 - val_accuracy: 0.5720\n","Epoch 77/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.7860 - accuracy: 0.6981 - val_loss: 0.8874 - val_accuracy: 0.6809\n","Epoch 78/100\n","10/10 [==============================] - 1s 136ms/step - loss: 0.7989 - accuracy: 0.7037 - val_loss: 1.3160 - val_accuracy: 0.5409\n","Epoch 79/100\n","10/10 [==============================] - 1s 137ms/step - loss: 0.7423 - accuracy: 0.7106 - val_loss: 1.3494 - val_accuracy: 0.5642\n","Epoch 80/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.7509 - accuracy: 0.7098 - val_loss: 0.9648 - val_accuracy: 0.6693\n","Epoch 81/100\n","10/10 [==============================] - 2s 154ms/step - loss: 0.7678 - accuracy: 0.7076 - val_loss: 0.8440 - val_accuracy: 0.6848\n","Epoch 82/100\n","10/10 [==============================] - 1s 143ms/step - loss: 0.7200 - accuracy: 0.7189 - val_loss: 0.9465 - val_accuracy: 0.6342\n","Epoch 83/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.7044 - accuracy: 0.7435 - val_loss: 0.9510 - val_accuracy: 0.6187\n","Epoch 84/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.7237 - accuracy: 0.7124 - val_loss: 0.9248 - val_accuracy: 0.6498\n","Epoch 85/100\n","10/10 [==============================] - 1s 142ms/step - loss: 0.7154 - accuracy: 0.7271 - val_loss: 0.8101 - val_accuracy: 0.7004\n","Epoch 86/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.7015 - accuracy: 0.7292 - val_loss: 1.0170 - val_accuracy: 0.6459\n","Epoch 87/100\n","10/10 [==============================] - 1s 137ms/step - loss: 0.7008 - accuracy: 0.7258 - val_loss: 0.9278 - val_accuracy: 0.6498\n","Epoch 88/100\n","10/10 [==============================] - 1s 140ms/step - loss: 0.7316 - accuracy: 0.7258 - val_loss: 0.9256 - val_accuracy: 0.6537\n","Epoch 89/100\n","10/10 [==============================] - 1s 137ms/step - loss: 0.7234 - accuracy: 0.7202 - val_loss: 1.0316 - val_accuracy: 0.6537\n","Epoch 90/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.7369 - accuracy: 0.7158 - val_loss: 1.0741 - val_accuracy: 0.5759\n","Epoch 91/100\n","10/10 [==============================] - 1s 136ms/step - loss: 0.6991 - accuracy: 0.7266 - val_loss: 1.3074 - val_accuracy: 0.5914\n","Epoch 92/100\n","10/10 [==============================] - 1s 140ms/step - loss: 0.7058 - accuracy: 0.7331 - val_loss: 1.1740 - val_accuracy: 0.5681\n","Epoch 93/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.7448 - accuracy: 0.7180 - val_loss: 1.0398 - val_accuracy: 0.5837\n","Epoch 94/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.7600 - accuracy: 0.7106 - val_loss: 1.0654 - val_accuracy: 0.6304\n","Epoch 95/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.7594 - accuracy: 0.7124 - val_loss: 0.9177 - val_accuracy: 0.6732\n","Epoch 96/100\n","10/10 [==============================] - 1s 139ms/step - loss: 0.7213 - accuracy: 0.7206 - val_loss: 0.8536 - val_accuracy: 0.6887\n","Epoch 97/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.6756 - accuracy: 0.7413 - val_loss: 0.8761 - val_accuracy: 0.7198\n","Epoch 98/100\n","10/10 [==============================] - 1s 141ms/step - loss: 0.6822 - accuracy: 0.7431 - val_loss: 0.8921 - val_accuracy: 0.6770\n","Epoch 99/100\n","10/10 [==============================] - 1s 137ms/step - loss: 0.7629 - accuracy: 0.7054 - val_loss: 1.0025 - val_accuracy: 0.6148\n","Epoch 100/100\n","10/10 [==============================] - 1s 138ms/step - loss: 0.7677 - accuracy: 0.6981 - val_loss: 0.9899 - val_accuracy: 0.6304\n","81/81 [==============================] - 0s 4ms/step - loss: 0.9094 - accuracy: 0.6481\n","35/35 [==============================] - 0s 4ms/step - loss: 0.9205 - accuracy: 0.6512\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.9204573035240173, 0.6512261629104614]"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["Jako mój model skopiowałem z drobnymi modyfikacjami model z zajęć \"mega\", który był połączeniem wszystkich dotychczasowych narzędzi - BatchNormalization, RandomZoom i RandomFlip, Dropout, MaxPooling, Flatten. Zrezygnowałem tylko z EarlyStoppingu ze względu na to że na początku uczenia model radził sobie wyjątkowo stabilnie źle przez co poddawałby się za wcześnie. \n","Po tej początkowej fazie kilku iteracji niepowidzeń model poradził sobie całkiem nieźle bo osiągnał na zbiorze treningowym accuracy 0.65 a miejscami podczas uczenia nawet ponad 0.70. Jest to zdecydowanie lepiej niż preuczone modele 2 i 3 z zadania 2. Nie pobił on jednak modelu 1 z zadania 1 który miał wynik w okolicy 0.79. \n","Myślę, że przy doborze odpowiednich technik i liczb wyniki można by jeszcze trochę podciągnąć tak, aby dorównywał modelowi 1. Z drugiej strony model 1 jest już gotowy i dostosowanie go jest szybsze niż uczenie nowego modelu, którym dążymy jedynie do wyrównania a nie do znaczego polepszenia wyników. "],"metadata":{"id":"v9J2omGo34Hz"}},{"cell_type":"markdown","source":["To wszystko, dziękuję. Wypełniony notatnik zapisz jako .ipynb i oddaj w Teams. "],"metadata":{"id":"Eh2TKe3VE5iq"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0d9c0bd072fb4e8085aa9eb78f48e7cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a48e7fd1a3d4419927830d2effdb2ab","IPY_MODEL_8aec5db6a9224d7088a26cd29d91dbdd","IPY_MODEL_d4be86ddbced494a944fdb5cd0b6f29f"],"layout":"IPY_MODEL_7c1e21303e6d42638df9fc2203b9fa9e"}},"5a48e7fd1a3d4419927830d2effdb2ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd1086e6659b4531b1b8dbbee749f7e3","placeholder":"​","style":"IPY_MODEL_e2d2f32722d84a02bc1fba4566e3e6d7","value":"Dl Completed...: 100%"}},"8aec5db6a9224d7088a26cd29d91dbdd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c7c14aeafc948a38f340a2043f9950c","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a183270a0a66476486444e1303692c4d","value":5}},"d4be86ddbced494a944fdb5cd0b6f29f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed6d4694b84c4320a0691bca977deb10","placeholder":"​","style":"IPY_MODEL_341d982240754999bb8f5392922c7a63","value":" 5/5 [00:03&lt;00:00,  1.31 file/s]"}},"7c1e21303e6d42638df9fc2203b9fa9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd1086e6659b4531b1b8dbbee749f7e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2d2f32722d84a02bc1fba4566e3e6d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c7c14aeafc948a38f340a2043f9950c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a183270a0a66476486444e1303692c4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed6d4694b84c4320a0691bca977deb10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"341d982240754999bb8f5392922c7a63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}